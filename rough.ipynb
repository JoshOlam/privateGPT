{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model file at  /Users/josh/.cache/gpt4all/orca-mini-3b.ggmlv3.q4_0.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "objc[42698]: Class GGMLMetalClass is implemented in both /Users/josh/Documents/GitHub/privateGPT/pGPT_env/lib/python3.11/site-packages/gpt4all/llmodel_DO_NOT_MODIFY/build/libreplit-mainline-metal.dylib (0x10cd14228) and /Users/josh/Documents/GitHub/privateGPT/pGPT_env/lib/python3.11/site-packages/gpt4all/llmodel_DO_NOT_MODIFY/build/libllamamodel-mainline-metal.dylib (0x10cbdc228). One of the two will be used. Which one is undefined.\n",
      "llama.cpp: using Metal\n",
      "llama.cpp: loading model from /Users/josh/.cache/gpt4all/orca-mini-3b.ggmlv3.q4_0.bin\n",
      "llama_model_load_internal: format     = ggjt v3 (latest)\n",
      "llama_model_load_internal: n_vocab    = 32000\n",
      "llama_model_load_internal: n_ctx      = 2048\n",
      "llama_model_load_internal: n_embd     = 3200\n",
      "llama_model_load_internal: n_mult     = 240\n",
      "llama_model_load_internal: n_head     = 32\n",
      "llama_model_load_internal: n_head_kv  = 32\n",
      "llama_model_load_internal: n_layer    = 26\n",
      "llama_model_load_internal: n_rot      = 100\n",
      "llama_model_load_internal: n_gqa      = 1\n",
      "llama_model_load_internal: rnorm_eps  = 5.0e-06\n",
      "llama_model_load_internal: n_ff       = 8640\n",
      "llama_model_load_internal: freq_base  = 10000.0\n",
      "llama_model_load_internal: freq_scale = 1\n",
      "llama_model_load_internal: ftype      = 2 (mostly Q4_0)\n",
      "llama_model_load_internal: model size = 3B\n",
      "llama_model_load_internal: ggml ctx size =    0.07 MB\n",
      "llama_model_load_internal: mem required  = 2194.73 MB (+  650.00 MB per state)\n",
      "llama_new_context_with_model: kv self size  =  650.00 MB\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: using MPS\n",
      "ggml_metal_init: loading '/Users/josh/Documents/GitHub/privateGPT/pGPT_env/lib/python3.11/site-packages/gpt4all/llmodel_DO_NOT_MODIFY/build/ggml-metal.metal'\n",
      "ggml_metal_init: loaded kernel_add                            0x10b0a0560\n",
      "ggml_metal_init: loaded kernel_add_row                        0x10b0a5090\n",
      "ggml_metal_init: loaded kernel_mul                            0x10b0a5dd0\n",
      "ggml_metal_init: loaded kernel_mul_row                        0x10b0a76a0\n",
      "ggml_metal_init: loaded kernel_scale                          0x10b0a7010\n",
      "ggml_metal_init: loaded kernel_silu                           0x10b0a7f30\n",
      "ggml_metal_init: loaded kernel_relu                           0x10b0a8f30\n",
      "ggml_metal_init: loaded kernel_gelu                           0x10b0a9730\n",
      "ggml_metal_init: loaded kernel_soft_max                       0x10b0a9b00\n",
      "ggml_metal_init: loaded kernel_diag_mask_inf                  0x10b0a9d50\n",
      "ggml_metal_init: loaded kernel_get_rows_f16                   0x10b0aa750\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_0                  0x10d5431c0\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_1                  0x10d5434f0\n",
      "ggml_metal_init: loaded kernel_get_rows_q2_K                  0x10d5442f0\n",
      "ggml_metal_init: loaded kernel_get_rows_q3_K                  0x10d543d20\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_K                  0x10d544540\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_K                  0x10d544790\n",
      "ggml_metal_init: loaded kernel_get_rows_q6_K                  0x10d546970\n",
      "ggml_metal_init: loaded kernel_rms_norm                       0x11f670200\n",
      "ggml_metal_init: loaded kernel_norm                           0x11f670450\n",
      "ggml_metal_init: loaded kernel_mul_mat_f16_f32                0x10d546bc0\n",
      "ggml_metal_init: loaded kernel_mul_mat_q4_0_f32               0x10d547470\n",
      "ggml_metal_init: loaded kernel_mul_mat_q4_1_f32               0x10d547a40\n",
      "ggml_metal_init: loaded kernel_mul_mat_q2_K_f32               0x10d548160\n",
      "ggml_metal_init: loaded kernel_mul_mat_q3_K_f32               0x10d5486c0\n",
      "ggml_metal_init: loaded kernel_mul_mat_q4_K_f32               0x10adf8340\n",
      "ggml_metal_init: loaded kernel_mul_mat_q5_K_f32               0x10adf9200\n",
      "ggml_metal_init: loaded kernel_mul_mat_q6_K_f32               0x10adf9680\n",
      "ggml_metal_init: loaded kernel_rope                           0x10d548910\n",
      "ggml_metal_init: loaded kernel_alibi_f32                      0x10d549130\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f16                    0x10d549990\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f32                    0x10d549f80\n",
      "ggml_metal_init: loaded kernel_cpy_f16_f16                    0x10d54a500\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize = 10922.67 MB\n",
      "ggml_metal_init: hasUnifiedMemory             = true\n",
      "ggml_metal_init: maxTransferRate              = built-in GPU\n",
      "llama_new_context_with_model: max tensor size =    54.93 MB\n",
      "ggml_metal_add_buffer: allocated 'data            ' buffer, size =  1839.12 MB, ( 1839.77 / 10922.67)\n",
      "ggml_metal_add_buffer: allocated 'eval            ' buffer, size =     8.17 MB, ( 1847.94 / 10922.67)\n",
      "ggml_metal_add_buffer: allocated 'kv              ' buffer, size =   652.00 MB, ( 2499.94 / 10922.67)\n",
      "ggml_metal_add_buffer: allocated 'scr0            ' buffer, size =   220.00 MB, ( 2719.94 / 10922.67)\n",
      "ggml_metal_add_buffer: allocated 'scr1            ' buffer, size =   128.00 MB, ( 2847.94 / 10922.67)\n"
     ]
    }
   ],
   "source": [
    "from gpt4all import GPT4All\n",
    "model = GPT4All(\"orca-mini-3b.ggmlv3.q4_0.bin\")\n",
    "# output = model.generate(\"The capital of France is \", max_tokens=3)\n",
    "# print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nigeria is a country located in West Africa. It is the most populous country in Africa and has a diverse population of over 250 ethnic groups. The official language of Nigeria is English, but there are also many other languages spoken throughout the country. Nigeria is known for its oil reserves, which make up about 9% of the world's total oil production. It is also home to the largest economy in Africa and has a rapidly growing tourism industry due to its beautiful landscapes and cultural heritage.\n"
     ]
    }
   ],
   "source": [
    "output = model.generate(\"What do you know about Nigeria?\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " about the importance of being a good listener and how it can benefit you in both personal and professional settings.\n"
     ]
    }
   ],
   "source": [
    "output = model.generate(\"Write me a long poem\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pGPT_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
